{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://pa-legg.github.io/images/uwe_banner.png\">\n",
    "\n",
    "# UFCFFY-15-M Cyber Security Analytics 23-24\n",
    "\n",
    "## Portfolio Assignment: Worksheet 2\n",
    "\n",
    "## Conduct an investigation on a URL database to develop a DGA classification system using machine learning techniques\n",
    "---\n",
    "\n",
    "For this task, the company **\"UWEtech\"** enlist your help once more. They have identified a number of suspicious URLs on their logging systems, suspecting that these URLs contain various malware, and so require your expertise to investigate these further. Specifically, they seek a machine learning approach to identify the malware families as observed on their network.\n",
    "\n",
    "You will need to develop a machine learning tool using Python and scikit-learn that can identify URLs based on [Domain Generator Algorithms (DGA)](https://blog.malwarebytes.com/security-world/2016/12/explained-domain-generating-algorithm/), widely used by command and control malware to avoid static IP blocking.\n",
    "\n",
    "You need to demonstrate experimental design of appropriate feature engineering to characterise the data, that will be used to inform your machine learning classifiers. You should show **at least two** schemes of curating appropriate features, based on the raw data as provided, and show this impacts the performance of your classifier.\n",
    "\n",
    "You are also expected to utilise **3 different classifiers** using the scikit-learn library, and show how the model parameters can impact the performance of the classifiers. It is suggested that you use a Logistic Regression, a Random Forest Classifier, and a Multi-Layer Perceptron Classifier.\n",
    "\n",
    "Finally, you should investigate the **performance and explainability** of your classifiers. It is recommended that you use the confusion matrix approach along with performance metrics, to assess how your model performs as well as when and why misclassification may occur. In reporting your findings, you should explain and reflect on this to understand which malware families are more separable, and which are more challenging to classify, using this approach. It is expected that a good performing classifier will achieve over 90% accuracy - however you will be assessed on your experimental design in finding a suitable classifier to achieve this.\n",
    "\n",
    "**Dataset**: Please see the folder ***\"Portfolio Assignment\"*** under the Assignment tab on Blackboard for further detail related to the access and download of the necessary dataset.\n",
    "\n",
    "**Hint**: You should conduct research using the [scikit-learn documentation and API reference](https://scikit-learn.org/stable/user_guide.html), making full use of the sample code that has been provided for your to help guide your research. You should also research Shapley Additive Explanations, and utilise the [online documentation](https://shap.readthedocs.io/en/latest/index.html). You should also think about a suitable means of generating input features for your classifier that capture sequential properties of text data.\n",
    "\n",
    "### Assessment and Marking\n",
    "---\n",
    "The completion of this worksheet is worth **35%** of your portfolio assignment for the UFCFFY-15-M Cyber Security Analytics (CSA) module.\n",
    "\n",
    "This is an **unguided** task that will be graded against the following core criteria:\n",
    "\n",
    "* **A clear and iterative experimental approach for developing and refining the classifier to improve performance (10 Marks)**\n",
    "  * *For the higher mark band, it would be expected that you would show an initial experimental design, and then refine this through improving the feature engineering stage, subsequently improving the model performance.*\n",
    "* **Suitable feature engineering stages demonstrating at least two different methods and their performance (10 Marks)**\n",
    "  * *For the higher mark band, it would be expected that you would demonstrate two sensible approaches for curating features, with strong justification as to why they would characterise the data fairly.*\n",
    "* **Suitable use of the sci-kit machine learning library (5 Marks)**\n",
    "  * *For the higher mark band, it would be expected that you would show a good comprehension of the library usage.*\n",
    "* **Clear evaluation of ML performance and explainability (5 Marks)**\n",
    "  * *For the higher mark band, it would be expected that you would use confusion matrices to explain which malware classes are more separable, and which share similarity according to a well-trained model.*\n",
    "* **Clarity and presentation (5 Marks)**\n",
    "  * *For the higher mark band, it would be expected that your notebook is clear and concise, with good use of Markdown to annotate your work professionally.*\n",
    "\n",
    "### Submission Documents\n",
    "---\n",
    "\n",
    "Your submission for this task should include:\n",
    "\n",
    "- **1 Jupyter Notebook file (*.ipynb)**\n",
    "\n",
    "You should complete your work using the ipynb file provided (i.e., this document). Once you have completed your work, you should ensure that all code cells have been executed and then you should save your notebook. **Please note: Staff will NOT execute your notebook during marking. It is your responsibility to ensure that your saved notebook shows the code cell outputs as required.**\n",
    "\n",
    "The deadline for your portfolio submission is **THURSDAY 2ND MAY @ 14:00**. This assignment is eligible for the [48-hour late submission window](https://www.uwe.ac.uk/study/academic-information/personal-circumstances/late-submission-window), however module staff will not be able to assist with any queries after the deadline.\n",
    "\n",
    "Your portfolio submitted to Blackboard must contain 3 independent documents:\n",
    "\n",
    "- ***STUDENT_ID-TASK1.ipynb*** (your iPYNB with all cells executed)\n",
    "- ***STUDENT_ID-TASK2.ipynb*** (your iPYNB with all cells executed)\n",
    "- ***STUDENT_ID-TASK3.pdf*** (a PDF report of your research investigation)\n",
    "\n",
    "### Contact\n",
    "---\n",
    "\n",
    "Questions about this assignment should be directed to your module leader (Phil.Legg@uwe.ac.uk). You should use the [online Q&A form](https://forms.office.com/e/yxFJZDraRG) to ask questions related to this module and this assignment, as well as utilising the on-site teaching sessions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJd9B_B48hBc",
    "outputId": "7125c19b-27b3-4225-a2bc-f9d8ad265dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: tldextract in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: whois in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.20240129.2)\n",
      "Requirement already satisfied: pyopenssl in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.1.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: tld in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13)\n",
      "Requirement already satisfied: idna in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract) (3.6)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract) (2.0.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract) (3.13.1)\n",
      "Requirement already satisfied: cryptography<43,>=41.0.5 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyopenssl) (42.0.4)\n",
      "Requirement already satisfied: graphviz in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (2.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.12.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (5.20.0)\n",
      "Requirement already satisfied: six in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography<43,>=41.0.5->pyopenssl) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.1.0->tldextract) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.1.0->tldextract) (2024.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lesmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography<43,>=41.0.5->pyopenssl) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install colorama  tldextract whois pyopenssl  catboost tldextract tld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Xei5g4OhrtI0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstractmethod, ABCMeta\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernel_approximation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Nystroem\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numba'"
     ]
    }
   ],
   "source": [
    "# Import libraries as required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import seaborn as sns\n",
    "# Preparation for Logistic Regression\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "from numba import njit\n",
    "from abc import abstractmethod, ABCMeta\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from cuml import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# Parsing Urls\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import os.path\n",
    "import string\n",
    "import logging\n",
    "\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models from Scikit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model Evaluations\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Default settings of CSA Assessment 2\n",
    "from collections import Counter\n",
    "from timeit import timeit\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier, Perceptron\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from tldextract import extract as tld_extract\n",
    "from tld import get_tld, is_tld\n",
    "from tld.exceptions import TldDomainNotFound, TldBadUrl, TldIOError\n",
    "\n",
    "from colorama import Fore\n",
    "from datetime import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objects as go\n",
    "from wordcloud import WordCloud\n",
    "from gensim.models import Word2Vec\n",
    "import tldextract\n",
    "import hashlib\n",
    "import whois\n",
    "import warnings\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ7LwU2jOgLx"
   },
   "outputs": [],
   "source": [
    "def hash_encode(category):\n",
    "    hash_object = hashlib.md5(category.encode())\n",
    "    return int(hash_object.hexdigest(), 16) % (10 ** 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqMEmhA_rywx"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dga-24000.csv')\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZmM69G7rzJs",
    "outputId": "383a94ab-fbd9-4dda-c5cd-903d64be9209"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "data[\"label\"] = lb_make.fit_transform(data[\"Family\"])\n",
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "Uz9VZbfwcRre",
    "outputId": "a650f5b6-d676-4fed-c498-7aabdd3166ce"
   },
   "outputs": [],
   "source": [
    "# countplot\n",
    "plt.figure(figsize=(8,7))\n",
    "sns.countplot(x='label',data=data,hue='label', palette='magma', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "R8mOyP0Ezr-G",
    "outputId": "b28bdc16-6b71-4312-8dfe-1b597e5b8f51"
   },
   "outputs": [],
   "source": [
    "def url_length(url):\n",
    "    return len(str(url))\n",
    "\n",
    "data['url_length'] = data['Domain'].apply(lambda i: url_length(i))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXBF-aKlClob",
    "outputId": "a78f0610-9bed-42b1-d22d-0e2a460bb59c"
   },
   "outputs": [],
   "source": [
    "# Split into X & y and train/test\n",
    "X = data.drop(\"label\", axis=1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, shuffle=True, random_state=5)\n",
    "print(f\"X_train Shape : {X_train.shape}\")\n",
    "print(f\"Y_train Shape : {y_train.shape}\")\n",
    "print(f\"X_test  Shape : {X_test.shape}\")\n",
    "print(f\"Y_test  Shape : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2MYr30ZD5li"
   },
   "source": [
    "# Convert string into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4V-lP6CCluq",
    "outputId": "59adaca7-5612-4b40-bc1a-b048849f0f00"
   },
   "outputs": [],
   "source": [
    "# 1. Import OneHotEncoder and ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 2. Define the categorical features to transform\n",
    "categorical_features = [\"Domain\", \"Family\", \"url_length\"]\n",
    "# 3. Create an instance of OneHotEncoder\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# 4. Create an instance of ColumnTransformer\n",
    "transformer = ColumnTransformer([(\"one_hot\", # name\n",
    "                                  one_hot, # transformer\n",
    "                                  categorical_features)], # columns to transform\n",
    "                                  remainder=\"passthrough\") # what to do with the rest of the columns? (\"passthrough\" = leave unchanged)\n",
    "\n",
    "# 5. Turn the categorical features into numbers (this will return an array-like sparse matrix, not a DataFrame)\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMYSkIrmD_7D"
   },
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3I6-wPEeClxT",
    "outputId": "41c179cb-73fe-4ec1-b3bd-aa34b715962b"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create train and test splits with transformed_X\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create the model instance\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=5, n_jobs=-1) # n_estimators = 100 is the default\n",
    "\n",
    "# Fit the model on the numerical data (this errored before since our data wasn't fully numeric)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Score the model (returns r^2 metric by default, also called coefficient of determination, higher is better)\n",
    "clf.score(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kY0sItKnDtCC",
    "outputId": "1e9914f8-3da1-47d2-fdb5-1819b56b19a1"
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hc7CfxnDtEU",
    "outputId": "f3c2e55f-0daa-4fa6-a013-e2f6ea701b9a"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikyTJ2zQEtPR"
   },
   "source": [
    "### Confusion Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyuYgdXwEjy1",
    "outputId": "e83c560a-d493-4125-d0e9-730fadc18476"
   },
   "outputs": [],
   "source": [
    "# View confusion matrix for test data and predictions\n",
    "confusion_matrix(y_test,  y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "_rSDkYS3DtGl",
    "outputId": "2f551526-be8e-4888-9981-fc750886046c"
   },
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_test, y_pred_test)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVdw7jT0EqEC"
   },
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45lk1VJ5DtJD",
    "outputId": "59cc2431-e17c-4e15-a6de-1454cacce5b4"
   },
   "outputs": [],
   "source": [
    "# View the classification report for test data and predictions\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2E1GtNGWWSu"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "vnWIcqOKP814",
    "outputId": "48022f97-86ce-4850-e227-a53aae725811"
   },
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "5WIjfpZbrIuq",
    "outputId": "994bb222-23ff-4452-a8b7-ec690d66265b"
   },
   "outputs": [],
   "source": [
    "count = data['Family'].value_counts()\n",
    "colors = [\n",
    "    '#FF6633', '#FFB399', '#FF33FF', '#FFFF99', '#00B3E6',\n",
    "    '#E6B333', '#3366E6', '#999966', '#99FF99', '#B34D4D',\n",
    "    '#FF6633', '#FFB399', '#FF33FF', '#FFFF99', '#00B3E6',\n",
    "    '#E6B333', '#3366E6', '#999966', '#99FF99', '#B34D4D',\n",
    "    '#FF6633', '#FFB399', '#FF33FF', '#FFFF99', '#00B3E6',\n",
    "]\n",
    "fig = go.Figure(data=[go.Bar(x=count.index, y=count, marker=dict(color=colors))])\n",
    "fig.update_layout(\n",
    "    xaxis_title='Types',\n",
    "    yaxis_title='Count',\n",
    "    title='Count of Different Types of URLs',\n",
    "    plot_bgcolor='black',\n",
    "    paper_bgcolor='black',\n",
    "    font=dict(color='white')\n",
    ")\n",
    "fig.update_xaxes(tickfont=dict(color='white'))\n",
    "fig.update_yaxes(tickfont=dict(color='white'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g62l-GEFsIyF"
   },
   "outputs": [],
   "source": [
    "def extract_root_domain(url):\n",
    "    extracted = tldextract.extract(url)\n",
    "    root_domain = extracted.domain\n",
    "    return root_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z57xriIOyl5G"
   },
   "outputs": [],
   "source": [
    "def extract_tld(url):\n",
    "    tld = url.split(\".\")[-1]\n",
    "    return \".\" + tld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_v_GuKls-3D"
   },
   "outputs": [],
   "source": [
    "df['root_domain'] = df['Domain'].apply(lambda x: extract_root_domain(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "NAwpj56SwY3K",
    "outputId": "fc921527-f829-48cd-b599-119a2d9eaac7"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXCuvkgnwuKK",
    "outputId": "b5e1213c-fb8a-4e6b-e8a1-dc530f96875d"
   },
   "outputs": [],
   "source": [
    "df['root_domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xztQkuJBw1rF"
   },
   "outputs": [],
   "source": [
    "df['domain_name'] = df['Domain'].apply(extract_tld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "qeRTyCwzyuQE",
    "outputId": "0f34a534-978d-4517-8fa1-0612a97f3731"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5duBEumyzcY",
    "outputId": "8f57803a-fd02-47ba-822a-7ac62394b88e"
   },
   "outputs": [],
   "source": [
    "df['domain_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "I_cbZq3O2Sa8",
    "outputId": "d041707f-4bf1-4bd4-b0b0-45dc54fc3853"
   },
   "outputs": [],
   "source": [
    "count = df['domain_name'].value_counts()\n",
    "colors = [\n",
    "    '#FF6633', '#FFB399', '#FF33FF', '#FFFF99', '#00B3E6',\n",
    "    '#E6B333', '#3366E6', '#999966', '#99FF99', '#B34D4D',\n",
    "    '#FF6633', '#FFB399', '#FF33FF', '#FFFF99', '#00B3E6',\n",
    "    '#E6B333', '#3366E6', '#999966', '#99FF99', '#B34D4D',\n",
    "    '#FF6633', '#FFB399', '#FF33FF', '#FFFF99', '#00B3E6',\n",
    "]\n",
    "fig = go.Figure(data=[go.Bar(x=count.index, y=count, marker=dict(color=colors))])\n",
    "fig.update_layout(\n",
    "    xaxis_title='Types',\n",
    "    yaxis_title='Count',\n",
    "    title='Count of Different Types of URLs',\n",
    "    plot_bgcolor='black',\n",
    "    paper_bgcolor='black',\n",
    "    font=dict(color='white')\n",
    ")\n",
    "fig.update_xaxes(tickfont=dict(color='white'))\n",
    "fig.update_yaxes(tickfont=dict(color='white'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZ0kNclA1IJD",
    "outputId": "f1da5787-1b24-48f1-eb50-dfa23983ae18"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nK49QfTt1h8w",
    "outputId": "9035e6ba-f8fb-4f44-b7a6-446d11c4afdd"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "LZeF5a3S-pT_",
    "outputId": "f1ca3898-89c7-415c-f718-fe5e14eed3eb"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9N8OzTpJ5FS"
   },
   "outputs": [],
   "source": [
    "# create cv object\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSG9xQDQJzv4",
    "outputId": "63bc8264-25fd-4f47-97fc-97c2493774f6"
   },
   "outputs": [],
   "source": [
    "cx = cv.fit_transform(df.root_domain) # transform all text which we tokenize and stemed\n",
    "cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rf_wRiG2LNHx",
    "outputId": "bbb71a83-f727-4a7b-d609-2741cabd430a"
   },
   "outputs": [],
   "source": [
    "cx.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EllMh318LNKJ"
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(cx, df.label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzWJL8h4Jofg"
   },
   "outputs": [],
   "source": [
    "# create lr object\n",
    "lr = LogisticRegression(solver='liblinear',penalty='l2',C=1.0, max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "whQX_3EOLfla",
    "outputId": "fd4dd1d2-e68c-426e-846b-5cf6c64cfe2f"
   },
   "outputs": [],
   "source": [
    "lr.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJmxBlduMd4p",
    "outputId": "da7f67fc-5b64-4f35-f8b7-db4f851495dd"
   },
   "outputs": [],
   "source": [
    "lr.score(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "MQfuoQ8yVW5H",
    "outputId": "c32b4596-4ec4-4beb-dd44-16a7b7338c9a"
   },
   "outputs": [],
   "source": [
    "lr.fit(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6YVlqcdLhiw",
    "outputId": "4e86c960-88d0-406a-eabc-2052fee12ea7"
   },
   "outputs": [],
   "source": [
    "lr.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9VsnVAF_K9u"
   },
   "outputs": [],
   "source": [
    "y_pred1 = lr.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yc_U2ZrE_ae2",
    "outputId": "ddea09bb-fa81-4d3f-ac25-ec60c07ef246"
   },
   "outputs": [],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icTB64ajJsBo",
    "outputId": "0c734815-8a58-412f-9328-3d611fb10cd8"
   },
   "outputs": [],
   "source": [
    "accuracy1 = accuracy_score(testY, y_pred1)\n",
    "print(\"test Accuracy:\", accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbSGvgEebyJ2"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2DDiPUN4kYl",
    "outputId": "1b3a54d9-cfee-4f90-8e62-b720fbe368cc"
   },
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(testY, y_pred1)\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "0jVohy8PabIe",
    "outputId": "44d6548d-b8f8-4add-e7d7-390c6b9fa9e2"
   },
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix2 = confusion_matrix(testY, y_pred1)\n",
    "matrix2 = matrix2.astype('float') / matrix2.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix2, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AntMh6714khl"
   },
   "source": [
    "# Multi-Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS5p3Eoi4myF"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "z0iPU3V64nF9",
    "outputId": "635b6d7f-b81b-4596-95db-c04d6585df4a"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1W5hkESi4nIO",
    "outputId": "5e2643ad-c903-4839-e63c-63119ca89d9d"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrtpG9bq4nKu"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "peh_vectors = count_vectorizer.fit_transform(df[\"Domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uwvnAi74nNQ"
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(peh_vectors, df[\"url_length\"], shuffle = True, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "WzRKl62r4nQG",
    "outputId": "57805f80-c478-4df9-bf4a-4246c90e8823"
   },
   "outputs": [],
   "source": [
    "mlp_peh = MLPClassifier(hidden_layer_sizes = (6,5), random_state = 3)\n",
    "\n",
    "mlp_peh.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRnZfMkWX5p7",
    "outputId": "16aa2512-3c99-4e13-a94c-efb7e60bb856"
   },
   "outputs": [],
   "source": [
    "mlp_peh.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "rzLnvWeOX4bo",
    "outputId": "f86af0ef-bcce-4085-da9a-96fea5a87a89"
   },
   "outputs": [],
   "source": [
    "mlp_peh.fit(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7ERH3SuX-Y1",
    "outputId": "1500f2f0-95c1-408d-efb6-f5e9d0da1364"
   },
   "outputs": [],
   "source": [
    "mlp_peh.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWbnRmT6XWX7",
    "outputId": "93b5be0d-c073-4f86-a934-6e5c7e94d6d6"
   },
   "outputs": [],
   "source": [
    "ypred = mlp_peh.predict(Xtest)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMan7NytXaD1",
    "outputId": "a876554d-a94f-41ed-ea74-2a4cf0d53949"
   },
   "outputs": [],
   "source": [
    "accuracy_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hi699vpMbnAm"
   },
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8hwePgNXoo2",
    "outputId": "807e8378-976b-440e-ff3d-c194a7bc2ab7"
   },
   "outputs": [],
   "source": [
    "# View the classification report for test data and predictions\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6Yv31bEbsBH"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr0f1WGnb7qO",
    "outputId": "c337dec9-b92c-43d8-8d37-e6ddf08ec263"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ytest, ypred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "71MPKa2NZz5E",
    "outputId": "12eea024-964a-4d14-fd2e-58b6bf53aa51"
   },
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matri = confusion_matrix(ytest, ypred)\n",
    "matri = matri.astype('float') / matri.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matri, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Multi-Layer Perceptron Classifier ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7s-uhPyZ3d7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
